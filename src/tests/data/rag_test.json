[
    {
        "question": "what is Rhode Island SB 146 act?",
        "expected_output": "The Rhode Island SB 146, known as the Consumer Protection Gaming Act, was introduced on February 1, 2023, and took effect immediately upon passage. It aims to safeguard gaming consumers from potential manipulation or harm by prohibiting the use of facial recognition, biometric recognition technologies, and certain AI-driven or automated decision-making systems in video-lottery terminals and online betting applications. Specifically, the law bans algorithmic programs that modify gaming outcomes based on a user's betting history to encourage increased wagers and prohibits the use of cognitive-behavioral techniques to condition users into extended play. However, it excludes standardized rewards programs from these restrictions. The law applies to all sports betting applications and licensed vendors in Rhode Island, reflecting the state's commitment to ethical AI use and consumer protection in the gaming industry, and remains in effect unless amended or repealed.",
        "relevant_documents": ["380"]
    },
    {
        "question": "what is Securing Growth and Robust Leadership in American Aviation Act, Sec. 1028 ('Air Traffic Control Training')?",
        "expected_output": "Section 1028 of the Securing Growth and Robust Leadership in American Aviation Act, enacted on May 16, 2024, mandates the Administrator of the Federal Aviation Administration (FAA) to implement a research program aimed at modernizing and improving on-the-job training for air traffic controllers using advanced technologies such as artificial intelligence, machine learning, and virtual reality. The initiative emphasizes collaboration with labor organizations and relevant stakeholders to assess the effectiveness, safety, and knowledge retention benefits of these technologies. The Act requires the FAA to submit a report detailing its findings to Congress by May 16, 2025, and explicitly states that the implementation of this research program must not delay the ongoing installation of tower simulation systems at FAA air traffic facilities.",
        "relevant_documents": ["839"]
    },
    {
        "question": "what is Anthropic Responsible Scaling Policy?",
        "expected_output": "Enacted on October 15, 2024, the Anthropic Responsible Scaling Policy establishes AI Safety Level Standards (ASLs) to guide the safe testing, deployment, and security of AI models, with ASL-2 serving as the baseline for current systems and higher standards like ASL-3 required for models with higher-risk capabilities, such as those involving Chemical, Biological, Radiological, and Nuclear (CBRN) weapon development or autonomous AI research. The policy defines capability thresholds that trigger additional safeguards, mandates specific safety and security measures for high-risk models, and includes governance mechanisms such as appointing a Responsible Scaling Officer, ensuring public transparency, and maintaining internal compliance procedures. It also commits to notifying relevant U.S. Government entities and engaging external experts if a model exceeds ASL-2. Reviewed last on September 19, 2023, the policy underscores Anthropicâ€™s proactive and ethical approach to AI development by prioritizing risk assessment and responsible scaling practices.",
        "relevant_documents": ["768"]
    },
    {
        "question": "what is Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047)?",
        "expected_output": "The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047), set to begin implementation on January 1, 2026, introduces comprehensive regulations for developers of advanced AI models in California, emphasizing responsible innovation and risk mitigation. The Act mandates robust cybersecurity protections, full shutdown capabilities, and detailed risk assessments, along with annual independent audits whose redacted findings must be publicly disclosed. Developers are required to report AI safety incidents to the Attorney General within 72 hours, and non-compliance may result in civil penalties. To support oversight, the Act establishes the Board of Frontier Models, tasked with updating AI model thresholds and auditing procedures annually starting in 2026. It also introduces CalCompute, a public cloud computing cluster designed to facilitate AI research. Overall, the Act aims to ensure the safe development and deployment of high-capacity AI systems through transparent governance and strict safety standards.",
        "relevant_documents": ["1163"]
    },
    {
        "question": "What is AI Safety Governance Framework v1.0 (National Technical Committee 260 on Cybersecurity of SAC)?",
        "expected_output": "The AI Safety Governance Framework v1.0, developed by the National Technical Committee 260 on Cybersecurity of SAC, provides foundational guidelines for ensuring the safety, security, and responsible deployment of artificial intelligence systems through a multi-stakeholder approach involving government, industry, and academia. It establishes a Task Force under the Cybersecurity and Infrastructure Security Agency (CISA) to coordinate AI safety efforts, encourages collaboration across federal and non-governmental entities, and mandates regular assessments and updates of AI safety initiatives in response to evolving technological challenges. The framework requires biannual reporting to Congress, prioritizes compliance with privacy and civil liberties standards, and includes measures to promote secure AI adoption while identifying workforce gaps in the sector. Though its enactment date is yet to be determined, the framework is set to remain in effect for five years from enactment and reflects a comprehensive strategy to address cybersecurity, ethical risks, and regulatory alignment in the AI ecosystem.",
        "relevant_documents": ["1802"]
    }
]